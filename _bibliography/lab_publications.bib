
@article{landgraf_analysis_2011,
	title = {Analysis of the {Waggle} {Dance} {Motion} of {Honeybees} for the {Design} of a {Biomimetic} {Honeybee} {Robot}},
	volume = {6},
	issn = {1932-6203},
	url = {http://dx.plos.org/10.1371/journal.pone.0021354},
	doi = {10.1371/journal.pone.0021354},
	language = {en},
	number = {8},
	urldate = {2017-10-23},
	journal = {PLoS ONE},
	author = {Landgraf, Tim and Rojas, Raúl and Nguyen, Hai and Kriegel, Fabian and Stettin, Katja},
	editor = {Krapp, Holger G.},
	month = aug,
	year = {2011},
	keywords = {peer-reviewed},
	pages = {e21354},
	file = {journal.pone.0021354.PDF:C\:\\Users\\Tim\\Zotero\\storage\\74ESK9DB\\journal.pone.0021354.PDF:application/pdf}
}

@inproceedings{landgraf_imitation_2012,
	title = {Imitation of the honeybee dance communication system by means of a biomimetic robot},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-31525-1_12},
	urldate = {2016-12-20},
	booktitle = {Conference on {Biomimetic} and {Biohybrid} {Systems}},
	publisher = {Springer},
	author = {Landgraf, Tim and Oertel, Michael and Kirbach, Andreas and Menzel, Randolf and Rojas, Raúl},
	year = {2012},
	keywords = {peer-reviewed},
	pages = {132--143},
	file = {Landgraf et al._2012_Imitation of the honeybee dance communication system by means of a biomimetic robot.pdf:C\:\\Users\\Tim\\Zotero\\storage\\X5N679X3\\Landgraf et al._2012_Imitation of the honeybee dance communication system by means of a biomimetic robot.pdf:application/pdf}
}

@phdthesis{landgraf_robobee:_2013,
	title = {{RoboBee}: {A} {Biomimetic} {Honeybee} {Robot} for the {Analysis} of the {Dance} {Communication} {System}},
	shorttitle = {{RoboBee}},
	url = {http://www.diss.fu-berlin.de/diss/receive/FUDISS_thesis_000000094818?lang=de},
	urldate = {2016-11-29},
	school = {Berlin, Freie Universität Berlin, 2013},
	author = {Landgraf, Tim},
	year = {2013}
}

@inproceedings{landgraf_neurocopter:_2013,
	title = {{NeuroCopter}: neuromorphic computation of {6D} ego-motion of a quadcopter},
	shorttitle = {{NeuroCopter}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-39802-5_13},
	urldate = {2016-11-29},
	booktitle = {Conference on {Biomimetic} and {Biohybrid} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Landgraf, Tim and Wild, Benjamin and Ludwig, Tobias and Nowak, Philipp and Helgadottir, Lovisa and Daumenlang, Benjamin and Breinlinger, Philipp and Nawrot, Martin and Rojas, Raúl},
	year = {2013},
	keywords = {peer-reviewed},
	pages = {143--153}
}

@article{hussaini_sleep_2009,
	title = {Sleep deprivation affects extinction but not acquisition memory in honeybees},
	volume = {16},
	url = {http://learnmem.cshlp.org/content/16/11/698.short},
	number = {11},
	urldate = {2016-11-29},
	journal = {Learning \& memory},
	author = {Hussaini, Syed Abid and Bogusch, Lisa and Landgraf, Tim and Menzel, Randolf},
	year = {2009},
	keywords = {peer-reviewed},
	pages = {698--705}
}

@inproceedings{landgraf_multi-agent_2012,
	title = {A {Multi}-agent {Platform} for {Biomimetic} {Fish}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-31525-1_44},
	urldate = {2016-11-29},
	booktitle = {Conference on {Biomimetic} and {Biohybrid} {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Landgraf, Tim and Akkad, Rami and Nguyen, Hai and Clément, Romain O. and Krause, Jens and Rojas, Raúl},
	year = {2012},
	keywords = {peer-reviewed},
	pages = {365--366}
}

@article{jin_walking_2014,
	title = {Walking bumblebees memorize panorama and local cues in a laboratory test of navigation},
	volume = {97},
	url = {http://www.sciencedirect.com/science/article/pii/S0003347214003273},
	urldate = {2016-11-29},
	journal = {Animal Behaviour},
	author = {Jin, Nanxiang and Landgraf, Tim and Klein, Simon and Menzel, Randolf},
	year = {2014},
	keywords = {peer-reviewed},
	pages = {13--23},
	file = {[PDF] from researchgate.net:C\:\\Users\\Tim\\Zotero\\storage\\JA7APBNT\\Jin et al. - 2014 - Walking bumblebees memorize panorama and local cue.pdf:application/pdf}
}

@inproceedings{landgraf_interactive_2013,
	title = {Interactive robotic fish for the analysis of swarm behavior},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-38703-6_1},
	urldate = {2016-11-29},
	booktitle = {International {Conference} in {Swarm} {Intelligence}},
	publisher = {Springer Berlin Heidelberg},
	author = {Landgraf, Tim and Nguyen, Hai and Forgo, Stefan and Schneider, Jan and Schröer, Joseph and Krüger, Christoph and Matzke, Henrik and Clément, Romain O. and Krause, Jens and Rojas, Raúl},
	year = {2013},
	keywords = {peer-reviewed},
	pages = {1--10},
	file = {[PDF] from researchgate.net:C\:\\Users\\Tim\\Zotero\\storage\\M3D38ERD\\Landgraf et al. - 2013 - Interactive robotic fish for the analysis of swarm.pdf:application/pdf}
}

@article{landgraf_design_2008,
	title = {Design and development of a robotic bee for the analysis of honeybee dance communication},
	volume = {5},
	url = {http://www.tandfonline.com/doi/abs/10.1080/11762320802617552},
	number = {3},
	urldate = {2016-11-29},
	journal = {Applied Bionics and Biomechanics},
	author = {Landgraf, T. and Moballegh, H. and Rojas, R.},
	year = {2008},
	keywords = {peer-reviewed},
	pages = {157--164}
}

@inproceedings{helgadottir_conditioned_2013,
	title = {Conditioned behavior in a robot controlled by a spiking neural network},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6696078},
	urldate = {2016-11-29},
	booktitle = {Neural {Engineering} ({NER}), 2013 6th {International} {IEEE}/{EMBS} {Conference} on},
	publisher = {IEEE},
	author = {Helgadóttir, Lovísa Irpa and Haenicke, Joachim and Landgraf, Tim and Rojas, Raul and Nawrot, Martin P.},
	year = {2013},
	keywords = {peer-reviewed},
	pages = {891--894}
}

@article{bierbach_insights_2018,
	title = {Insights into the {Social} {Behavior} of {Surface} and {Cave}-{Dwelling} {Fish} ({Poecilia} mexicana) in {Light} and {Darkness} through the {Use} of a {Biomimetic} {Robot}},
	volume = {5},
	issn = {2296-9144},
	url = {http://journal.frontiersin.org/article/10.3389/frobt.2018.00003/full},
	doi = {10.3389/frobt.2018.00003},
	urldate = {2018-02-13},
	journal = {Frontiers in Robotics and AI},
	author = {Bierbach, David and Lukas, Juliane and Bergmann, Anja and Elsner, Kristiane and Höhne, Leander and Weber, Christiane and Weimar, Nils and Arias-Rodriguez, Lenin and Mönck, Hauke J. and Nguyen, Hai and Romanczuk, Pawel and Landgraf, Tim and Krause, Jens},
	month = feb,
	year = {2018},
	keywords = {peer-reviewed}
}

@techreport{landgraf_tracking_2007,
	title = {Tracking honey bee dances from sparse optical flow fields},
	url = {http://www.diss.fu-berlin.de/docs/servlets/MCRFileNodeServlet/FUDOCS_derivate_000000000829/2007_11.pdf},
	author = {Landgraf, Tim and Rojas, Raúl},
	year = {2007},
	file = {Landgraf and Rojas - 2007 - Tracking honey bee dances from sparse optical flow.pdf:C\:\\Users\\Tim\\Zotero\\storage\\TP64JRC9\\Landgraf and Rojas - 2007 - Tracking honey bee dances from sparse optical flow.pdf:application/pdf}
}

@inproceedings{landgraf_biomimetic_2010,
	title = {A biomimetic honeybee robot for the analysis of the honeybee dance communication system},
	booktitle = {Intelligent {Robots} and {Systems} ({IROS}), 2010 {IEEE}/{RSJ} {International} {Conference} on},
	publisher = {IEEE},
	author = {Landgraf, Tim and Oertel, Michael and Rhiel, Daniel and Rojas, Raúl},
	year = {2010},
	keywords = {peer-reviewed},
	pages = {3097--3102}
}

@inproceedings{worm_electro-communicating_2014,
	title = {Electro-communicating dummy fish initiate group behavior in the weakly electric fish {Mormyrus} rume},
	booktitle = {Conference on {Biomimetic} and {Biohybrid} {Systems}},
	publisher = {Springer, Cham},
	author = {Worm, Martin and Landgraf, Tim and Nguyen, Hai and von der Emde, Gerhard},
	year = {2014},
	keywords = {peer-reviewed},
	pages = {446--448}
}

@inproceedings{landgraf_blending_2014,
	title = {Blending in with the shoal: robotic fish swarms for investigating strategies of group formation in guppies},
	booktitle = {Conference on {Biomimetic} and {Biohybrid} {Systems}},
	publisher = {Springer, Cham},
	author = {Landgraf, Tim and Nguyen, Hai and Schröer, Joseph and Szengel, Angelika and Clément, Romain JG and Bierbach, David and Krause, Jens},
	year = {2014},
	keywords = {peer-reviewed},
	pages = {178--189}
}

@inproceedings{helgadottir_robotic_2012,
	title = {A {Robotic} {Platform} for {Spiking} {Neural} {Control} {Architectures}},
	booktitle = {Bernstein {Conference} 2012, {Munich}, {Germany}, 12 {Sep} - 14 {Sep}, 2012.},
	publisher = {Frontiers in Computational Neuroscience},
	author = {Helgadottir, Lovisa Irpa and Haenicke, Joachim and Landgraf, Tim and Nawrot, Martin Paul},
	year = {2012},
	pages = {154}
}

@inproceedings{meyer_digital_2011,
	title = {A digital receptor neuron connecting remote sensor hardware to spiking neural networks},
	booktitle = {{BC11} : {Computational} {Neuroscience} \& {Neurotechnology} {Bernstein} {Conference} \& {Neurex} {Annual} {Meeting} 2011, {Freiburg}, {Germany}, 4 {Oct} - 6 {Oct}, 2011.},
	publisher = {Frontiers Neuroscience},
	author = {Meyer, Jan and Haenicke, Joachim and Landgraf, Tim and Schmuker, Michael and Rojas, Raúl and Nawrot, Martin},
	year = {2011}
}

@inproceedings{landgraf_blending_2011,
	title = {Blending into the {Hive}: {A} {Novel} {Biomimetic} {Honeybee} {Robot} for the {Analysis} of the {Dance} {Communication} {System}.},
	booktitle = {International {Workshop} on {Bio}-{Inspired} {Robots}, {Nantes} {April} 6-8},
	publisher = {Ecole des Mines, IRCCYN LAB},
	author = {Landgraf, Tim},
	year = {2011},
	keywords = {peer-reviewed}
}

@article{landgraf_robofish:_2016,
	title = {{RoboFish}: increased acceptance of interactive robotic fish with realistic eyes and natural motion patterns by live {Trinidadian} guppies},
	volume = {11},
	number = {1},
	journal = {Bioinspiration \& Biomimetics},
	author = {Landgraf, Tim and Bierbach, David and Nguyen, Hai and Muggelberg, Nadine and Romanczuk, Pawel and Krause, Jens},
	year = {2016},
	keywords = {peer-reviewed},
	pages = {015001},
	file = {[PDF] from researchgate.net:C\:\\Users\\Tim\\Zotero\\storage\\7CP7I5V2\\Landgraf et al. - 2016 - RoboFish increased acceptance of interactive robo.pdf:application/pdf}
}

@incollection{landgraf_kunstliche_2017,
	title = {Künstliche {Mini}-{Gehirne} für {Roboter}},
	booktitle = {Planen und {Handeln}},
	publisher = {Springer Spektrum, Wiesbaden},
	author = {Landgraf, Tim and Nawrot, Martin},
	year = {2017},
	pages = {135--150}
}

@article{lam_dancing_2017,
	title = {Dancing attraction: followers of honey bee tremble and waggle dances exhibit similar behaviors},
	journal = {Biology open},
	author = {Lam, Calvin and Li, Yanlei and Landgraf, Tim and Nieh, James},
	year = {2017},
	keywords = {peer-reviewed},
	pages = {bio--025445}
}

@techreport{landgraf_dancing_2018,
	title = {Dancing {Honey} bee {Robot} {Elicits} {Dance}-{Following} and {Recruits} {Foragers}},
	author = {Landgraf, Tim and Bierbach, David and Kirbach, Andreas and Cusing, Rachel and Oertel, Michael and Lehmann, Konstantin and Greggers, Uwe and Menzel, Randolf and Rojas, Raúl},
	year = {2018}
}

@techreport{monck_biotracker:_2018,
	title = {{BioTracker}: {An} {Open}-{Source} {Computer} {Vision} {Framework} for {Visual} {Animal} {Tracking}},
	author = {Mönck, Hauke Jürgen and Jörg, Andreas and von Falkenhausen, Tobias and Tanke, Julian and Wild, Benjamin and Dormagen, David and Piotrowski, Jonas and Winklmayr, Claudia and Bierbach, David and Landgraf, Tim},
	year = {2018}
}

@article{muller_neural_2018,
	title = {A neural network model for familiarity and context learning during honeybee foraging flights},
	volume = {112},
	issn = {0340-1200, 1432-0770},
	url = {http://link.springer.com/10.1007/s00422-017-0732-z},
	doi = {10.1007/s00422-017-0732-z},
	language = {en},
	number = {1-2},
	urldate = {2018-12-13},
	journal = {Biological Cybernetics},
	author = {Müller, Jurek and Nawrot, Martin and Menzel, Randolf and Landgraf, Tim},
	month = apr,
	year = {2018},
	keywords = {peer-reviewed},
	pages = {113--126},
	file = {Müller et al. - 2018 - A neural network model for familiarity and context.pdf:C\:\\Users\\Tim\\Zotero\\storage\\8C4NMSVE\\Müller et al. - 2018 - A neural network model for familiarity and context.pdf:application/pdf}
}

@article{menzel_honeybees_2018,
	title = {Honeybees are {Guided} by {Learned} {Elongated} {Ground} {Structures}},
	volume = {12},
	issn = {1662-5153},
	url = {https://www.frontiersin.org/articles/10.3389/fnbeh.2018.00322/full},
	doi = {10.3389/fnbeh.2018.00322},
	abstract = {Elongated landscape features like forest edges, rivers, roads or boundaries of fields are particularly salient landmarks for navigating animals. Here we ask how honeybees learn such structures and how they are used during their homing flights after being released at an unexpected location (catch-and-release paradigm). The experiments were performed in two landscapes that differed with respect to their overall structure: a rather feature-less landscape, and one rich in close and far distant landmarks. We tested three different forms of learning: learning during orientation flights, learning during training to a feeding site, and learning during homing flights after release at an unexpected site within the explored area. We found that bees use elongated ground structures, e.g. a field boundary separating two pastures close to the hive (experiment 1), an irrigation channel (experiment 2), a hedgerow along which the bees were trained (experiment 3), a gravel road close to the hive and the feeder (experiment 4), a path along an irrigation channel with its vegetation close to the feeder (experiment 5) and a gravel road along which bees performed their homing flights (experiment 6). Discrimination and generalization between the learned linear landmarks and similar ones in the test area depend on their object properties (irrigation channel, gravel road, hedgerow) and their compass orientation. We conclude that elongated ground structures are embedded into multiple landscape features indicating that memory of these linear structures is one component of bee navigation. Elongated structures interact and compete with other references. Object identification is an important part of this process. The objects are characterized not only by their appearance but also by their alignment in the compass. Their salience is highest if both components are close to what had been learned. High similarity in appearance can compensate for (partial) compass misalignment, and vice versa.},
	language = {English},
	urldate = {2019-01-14},
	journal = {Frontiers in Behavioral Neuroscience},
	author = {Menzel, Randolf and Tison, Lea and Fischer-Nakai, Johannes and Cheeseman, James and Lehmann, Konstantin and Balbuena, Maria Sol and Chen, Xiuxian and Landgraf, Tim and Petrasch, Julian and Greggers, Uwe},
	year = {2018},
	keywords = {object recognition, navigation, Compass alignment, ground structures, guiding landmarks, sun compass, peer-reviewed}
}

@techreport{polster_reconstructing_2018,
	title = {Reconstructing the visual perception of honey bees in complex 3-{D} worlds},
	url = {http://arxiv.org/abs/1811.07560},
	abstract = {Over the last decades, honeybees have been a fascinating model to study insect navigation. While there is some controversy about the complexity of underlying neural correlates, the research of honeybee navigation makes progress through both the analysis of flight behavior and the synthesis of agent models. Since visual cues are believed to play a crucial role for the behavioral output of a navigating bee we have developed a realistic 3-dimensional virtual world, in which simulated agents can be tested, or in which the visual input of experimentally traced animals can be reconstructed. In this paper we present implementation details on how we reconstructed a large 3-dimensional world from aerial imagery of one of our field sites, how the distribution of ommatidia and their view geometry was modeled, and how the system samples from the scene to obtain realistic bee views. This system is made available as an open-source project to the community on {\textbackslash}url\{http://github.com/bioroboticslab/bee\_view\}.},
	urldate = {2019-01-14},
	author = {Polster, Johannes and Petrasch, Julian and Menzel, Randolf and Landgraf, Tim},
	month = nov,
	year = {2018},
	keywords = {Quantitative Biology - Quantitative Methods},
	file = {arXiv\:1811.07560 PDF:C\:\\Users\\Tim\\Zotero\\storage\\63TSDI5W\\Polster et al. - 2018 - Reconstructing the visual perception of honey bees.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\GX2VQGVL\\1811.html:text/html}
}

@article{bierbach_using_2018,
	title = {Using a robotic fish to investigate individual differences in social responsiveness in the guppy},
	volume = {5},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsos.181026},
	doi = {10.1098/rsos.181026},
	abstract = {Responding towards the actions of others is one of the most important behavioural traits whenever animals of the same species interact. Mutual influences among interacting individuals may modulate the social responsiveness seen and thus make it often difficult to study the level and individual variation in responsiveness. Here, open-loop biomimetic robots that provide standardized, non-interactive social cues can be a useful tool. These robots are not affected by the live animal's actions but are assumed to still represent valuable and biologically relevant social cues. As this assumption is crucial for the use of biomimetic robots in behavioural studies, we hypothesized (i) that meaningful social interactions can be assumed if live animals maintain individual differences in responsiveness when interacting with both a biomimetic robot and a live partner. Furthermore, to study the level of individual variation in social responsiveness, we hypothesized (ii) that individual differences should be maintained over the course of multiple tests with the robot. We investigated the response of live guppies (Poecilia reticulata) when allowed to interact either with a biomimetic open-loop-controlled fish robot—‘Robofish’—or with a live companion. Furthermore, we investigated the responses of live guppies when tested three times with Robofish. We found that responses of live guppies towards Robofish were weaker compared with those of a live companion, most likely as a result of the non-interactive open-loop behaviour of Robofish. Guppies, however, were consistent in their individual responses between a live companion and Robofish, and similar individual differences in response towards Robofish were maintained over repeated testing even though habituation to the test environment was detectable. Biomimetic robots like Robofish are therefore a useful tool for the study of social responsiveness in guppies and possibly other small fish species.},
	number = {8},
	urldate = {2019-02-11},
	journal = {Royal Society Open Science},
	author = {Bierbach, David and Landgraf, Tim and Romanczuk, Pawel and Lukas, Juliane and Nguyen, Hai and Wolf, Max and Krause, Jens},
	year = {2018},
	keywords = {peer-reviewed},
	pages = {181026},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\7HVL42GR\\Bierbach David et al. - Using a robotic fish to investigate individual dif.pdf:application/pdf;Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\RUVXW6RG\\rsos.html:text/html}
}

@techreport{wild_automatic_2018,
	title = {Automatic localization and decoding of honeybee markers using deep convolutional neural networks},
	url = {http://arxiv.org/abs/1802.04557},
	abstract = {The honeybee is a fascinating model animal to investigate how collective behavior emerges from (inter-)actions of thousands of individuals. Bees may acquire unique memories throughout their lives. These experiences affect social interactions even over large time frames. Tracking and identifying all bees in the colony over their lifetimes therefore may likely shed light on the interplay of individual differences and colony behavior. This paper proposes a software pipeline based on two deep convolutional neural networks for the localization and decoding of custom binary markers that honeybees carry from their first to the last day in their life. We show that this approach outperforms similar systems proposed in recent literature. By opening this software for the public, we hope that the resulting datasets will help advancing the understanding of honeybee collective intelligence.},
	urldate = {2019-05-27},
	author = {Wild, Benjamin and Sixt, Leon and Landgraf, Tim},
	month = feb,
	year = {2018},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1802.04557 PDF:C\:\\Users\\Tim\\Zotero\\storage\\V8F9R6NX\\Wild et al. - 2018 - Automatic localization and decoding of honeybee ma.pdf:application/pdf;arXiv\:1802.04557 PDF:C\:\\Users\\Tim\\Zotero\\storage\\ULNMJ4B3\\Wild et al. - 2018 - Automatic localization and decoding of honeybee ma.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\N2HZQ67T\\1802.html:text/html;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\7BCPY4V2\\1802.html:text/html;Wild et al. - 2018 - Automatic localization and decoding of honeybee ma.pdf:C\:\\Users\\Tim\\Zotero\\storage\\L76SKTYV\\Wild et al. - 2018 - Automatic localization and decoding of honeybee ma.pdf:application/pdf}
}

@article{boenisch_tracking_2018,
	title = {Tracking {All} {Members} of a {Honey} {Bee} {Colony} {Over} {Their} {Lifetime} {Using} {Learned} {Models} of {Correspondence}},
	volume = {5},
	issn = {2296-9144},
	url = {https://www.frontiersin.org/articles/10.3389/frobt.2018.00035/full},
	doi = {10.3389/frobt.2018.00035},
	abstract = {Computational approaches to the analysis of collective behavior in social insects increasingly rely on motion paths as an intermediate data layer from which one can infer individual behaviors or social interactions. Honey bees are a popular model for learning and memory. Previous experience has been shown to affect and modulate future social interactions. So far, no lifetime history observations have been reported for all bees of a colony. In a previous work we introduced a recording setup customized to track up to 4000 marked bees over several weeks. Due to detection and decoding errors of the bee markers, linking the correct correspondences through time is non-trivial. In this contribution we present an in-depth description of the underlying multi-step algorithm which produces motion paths, and also improves the marker decoding accuracy significantly. The proposed solution employs two classifiers to predict the correspondence of two consecutive detections in the first step, and two tracklets in the second. We automatically tracked {\textasciitilde}2000 marked honey bees over 10 weeks with inexpensive recording hardware using markers without any error correction bits. We found that the proposed two-step tracking reduced incorrect ID decodings from initially {\textasciitilde}13 \% to around 2 \% post-tracking. Alongside this paper, we publish the first trajectory dataset for all bees in a colony, extracted from {\textasciitilde}3 million images covering three days. We invite researchers to join the collective scientific effort to investigate this intriguing animal system. All components of our system are open-source.},
	language = {English},
	urldate = {2019-05-27},
	journal = {Frontiers in Robotics and AI},
	author = {Boenisch, Franziska and Rosemann, Benjamin and Wild, Benjamin and Dormagen, David and Wario, Fernando and Landgraf, Tim},
	year = {2018},
	note = {tex.ids= boenisch\_tracking\_2018},
	keywords = {Apis mellifera, social insects, honey bees, Lifetime History, tracking, trajectory, peer-reviewed},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\NTWTRNTZ\\Boenisch et al. - 2018 - Tracking All Members of a Honey Bee Colony Over Th.pdf:application/pdf;Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\YSN3WRT6\\Boenisch et al. - 2018 - Tracking All Members of a Honey Bee Colony Over Th.pdf:application/pdf}
}

@article{wario_automatic_2015,
	title = {Automatic methods for long-term tracking and the detection and decoding of communication dances in honeybees},
	volume = {3},
	issn = {2296-701X},
	doi = {10.3389/fevo.2015.00103},
	abstract = {The honeybee waggle dance communication system is an intriguing example of abstract animal communication and has been investigated thoroughly throughout the last seven decades. Typically, observables such as waggle durations or body angles are extracted manually either directly from the observation hive or from video recordings to quantify properties of the dance and related behaviors. In recent years, biology has proﬁted from automation, improving measurement precision, removing human bias, and accelerating data collection. We have developed technologies to track all individuals of a honeybee colony and to detect and decode communication dances automatically. In strong contrast to conventional approaches that focus on a small subset of the hive life, whether this regards time, space, or animal identity, our more inclusive system will help the understanding of the dance comprehensively in its spatial, temporal, and social context. In this contribution, we present full speciﬁcations of the recording setup and the software for automatic recognition of individually tagged bees and the decoding of dances. We discuss potential research directions that may beneﬁt from the proposed automation. Lastly, to exemplify the power of the methodology, we show experimental data and respective analyses from a continuous, experimental recording of 9 weeks duration.},
	language = {en},
	urldate = {2019-05-27},
	journal = {Frontiers in Ecology and Evolution},
	author = {Wario, Fernando and Wild, Benjamin and Couvillon, Margaret J. and Rojas, Raúl and Landgraf, Tim},
	month = sep,
	year = {2015},
	keywords = {waggle dance, animal behavior, animal tracking, honeybee, peer-reviewed},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\84S33XGB\\Wario et al. - 2015 - Automatic methods for long-term tracking and the d.pdf:application/pdf;Wario et al. - 2015 - Automatic methods for long-term tracking and the d.pdf:C\:\\Users\\Tim\\Zotero\\storage\\5LIJ56TL\\Wario et al. - 2015 - Automatic methods for long-term tracking and the d.pdf:application/pdf}
}

@article{worm_evidence_2018,
	title = {Evidence for mutual allocation of social attention through interactive signaling in a mormyrid weakly electric fish},
	volume = {115},
	copyright = {© 2018 . http://www.pnas.org/site/aboutpnas/licenses.xhtmlPublished under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	url = {https://www.pnas.org/content/115/26/6852},
	doi = {10.1073/pnas.1801283115},
	abstract = {Mormyrid weakly electric fish produce electric organ discharges (EODs) for active electrolocation and electrocommunication. These pulses are emitted with variable interdischarge intervals (IDIs) resulting in temporal discharge patterns and interactive signaling episodes with nearby conspecifics. However, unequivocal assignment of interactive signaling to a specific behavioral context has proven to be challenging. Using an ethorobotical approach, we confronted single individuals of weakly electric Mormyrus rume proboscirostris with a mobile fish robot capable of interacting both physically, on arbitrary trajectories, as well as electrically, by generating echo responses through playback of species-specific EODs, thus synchronizing signals with the fish. Interactive signaling by the fish was more pronounced in response to a dynamic echo playback generated by the robot than in response to playback of static random IDI sequences. Such synchronizations were particularly strong at a distance corresponding to the outer limit of active electrolocation, and when fish oriented toward the fish replica. We therefore argue that interactive signaling through echoing of a conspecific’s EODs provides a simple mechanism by which weakly electric fish can specifically address nearby individuals during electrocommunication. Echoing may thus enable mormyrids to mutually allocate social attention and constitute a foundation for complex social behavior and relatively advanced cognitive abilities in a basal vertebrate lineage.},
	language = {en},
	number = {26},
	urldate = {2019-10-01},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Worm, Martin and Landgraf, Tim and Prume, Julia and Nguyen, Hai and Kirschbaum, Frank and Emde, Gerhard von der},
	month = jun,
	year = {2018},
	keywords = {electrocommunication, ethorobotics, interactive signaling, social attention, peer-reviewed},
	pages = {6852--6857},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\TIHK2EP2\\Worm et al. - 2018 - Evidence for mutual allocation of social attention.pdf:application/pdf}
}

@misc{paffhausen_neural_2019,
	address = {Göttingen},
	title = {Neural correlates of mushroom body output neurons measured during flight of a harnessed honey bee on a quad copter},
	abstract = {Honey bee navigation is an actively investigated field but the knowledge about the neural correlates of goal directed long distance navigation remains mostly unknown. We recorded single neuron activity during flight in a natural environment. Bees were trained to a feeder 400 m from the hive. Spiking activity of high order interneurons (mushroom body extrinsic neurons of the A3 cluster) were recorded with extracellular electrodes at the alpha exit. The bees were attached to a quad copter together with the necessary amplifiers and data storing devices. The copter flew along the path the bees had taken during training to the feeder. Additional flight paths were flown at natural speed and height. The spike rates of the recorded neurons were analyzed with respect to the corresponding flight tracks. Preliminary analyses of the data showed a strong and repeated spike rate change whenever the copter turned in tight bends. Straight flights resulted in partially repeated spike rate changes along similar stretches of the flight path but with much higher variance. Further analyses are on the way. The next experiments will include other flight paths focusing on the question whether spiking activity can be related to object identification and localization, properties that are considered to be involved in mushroom body function.},
	author = {Paffhausen, Benjamin and Petrasch, Julian and Wild, Benjamin and Fuchs, Inga and Drexler, Helmut and Kuriatnyk, Oleksandra and Meurers, Thierry and Landgraf, Tim and Menzel, Randolf},
	month = jun,
	year = {2019},
	file = {Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\VXQP5I7L\\331981513_Neural_correlates_of_mushroom_body_output_neurons_measured_during_flight_of_a_harness.html:text/html}
}

@inproceedings{schulz_restricting_2019,
	title = {Restricting the {Flow}: {Information} {Bottlenecks} for {Attribution}},
	shorttitle = {Restricting the {Flow}},
	url = {https://openreview.net/forum?id=S1xWh1rYwB},
	abstract = {Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual...},
	urldate = {2020-03-16},
	author = {Schulz, Karl and Sixt, Leon and Tombari, Federico and Landgraf, Tim},
	month = sep,
	year = {2019},
	keywords = {peer-reviewed},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\DF4CUCA4\\Schulz et al. - 2019 - Restricting the Flow Information Bottlenecks for .pdf:application/pdf;Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\LR87CA6H\\forum.html:text/html}
}

@techreport{boenisch_tracking_2018-1,
	title = {Tracking all members of a honey bee colony over their lifetime},
	url = {http://arxiv.org/abs/1802.03192},
	abstract = {Computational approaches to the analysis of collective behavior in social insects increasingly rely on motion paths as an intermediate data layer from which one can infer individual behaviors or social interactions. Honey bees are a popular model for learning and memory. Previous experience has been shown to affect and modulate future social interactions. So far, no lifetime history observations have been reported for all bees of a colony. In a previous work we introduced a tracking system customized to track up to \$4000\$ bees over several weeks. In this contribution we present an in-depth description of the underlying multi-step algorithm which both produces the motion paths, and also improves the marker decoding accuracy significantly. We automatically tracked \$\{{\textbackslash}sim\}2000\$ marked honey bees over 10 weeks with inexpensive recording hardware using markers without any error correction bits. We found that the proposed two-step tracking reduced incorrect ID decodings from initially \$\{{\textbackslash}sim\}13{\textbackslash}\%\$ to around \$2{\textbackslash}\%\$ post-tracking. Alongside this paper, we publish the first trajectory dataset for all bees in a colony, extracted from \$\{{\textbackslash}sim\} 4\$ million images. We invite researchers to join the collective scientific effort to investigate this intriguing animal system. All components of our system are open-source.},
	urldate = {2020-09-19},
	author = {Boenisch, Franziska and Rosemann, Benjamin and Wild, Benjamin and Wario, Fernando and Dormagen, David and Landgraf, Tim},
	month = mar,
	year = {2018},
	note = {arXiv: 1802.03192},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tim\\Zotero\\storage\\JE5ESX8Q\\Boenisch et al. - 2018 - Tracking all members of a honey bee colony over th.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\7B9IXFX9\\1802.html:text/html}
}

@techreport{sixt_rendergan:_2017,
	title = {{RenderGAN}: {Generating} {Realistic} {Labeled} {Data}},
	shorttitle = {{RenderGAN}},
	url = {http://arxiv.org/abs/1611.01331},
	abstract = {Deep Convolutional Neuronal Networks (DCNNs) are showing remarkable performance on many computer vision tasks. Due to their large parameter space, they require many labeled samples when trained in a supervised setting. The costs of annotating data manually can render the use of DCNNs infeasible. We present a novel framework called RenderGAN that can generate large amounts of realistic, labeled images by combining a 3D model and the Generative Adversarial Network framework. In our approach, image augmentations (e.g. lighting, background, and detail) are learned from unlabeled data such that the generated images are strikingly realistic while preserving the labels known from the 3D model. We apply the RenderGAN framework to generate images of barcode-like markers that are attached to honeybees. Training a DCNN on data generated by the RenderGAN yields considerably better performance than training it on various baselines.},
	urldate = {2020-09-19},
	author = {Sixt, Leon and Wild, Benjamin and Landgraf, Tim},
	month = jan,
	year = {2017},
	note = {tex.ids= sixt\_rendergan:\_2016
arXiv: 1611.01331},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, GAN},
	file = {[PDF] from arxiv.org:C\:\\Users\\Tim\\Zotero\\storage\\U9IK2JRA\\Sixt et al. - 2016 - RenderGAN Generating Realistic Labeled Data.pdf:application/pdf;arXiv Fulltext PDF:C\:\\Users\\Tim\\Zotero\\storage\\TG5Y5XMR\\Sixt et al. - 2017 - RenderGAN Generating Realistic Labeled Data.pdf:application/pdf;arXiv\:1611.01331 PDF:C\:\\Users\\Tim\\Zotero\\storage\\6MNB3QP2\\Sixt et al. - 2016 - RenderGAN Generating Realistic Labeled Data.pdf:application/pdf;arXiv\:1611.01331 PDF:C\:\\Users\\Tim\\Zotero\\storage\\W3IPQKCY\\Sixt et al. - 2016 - RenderGAN Generating Realistic Labeled Data.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\LTB749VB\\1611.html:text/html;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\QVVAUA6F\\1611.html:text/html;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\8NGCRGYK\\1611.html:text/html;Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\62H28EUD\\Sixt et al. - 2016 - RenderGAN Generating Realistic Labeled Data.html:text/html}
}

@techreport{schulz_restricting_2020,
	title = {Restricting the {Flow}: {Information} {Bottlenecks} for {Attribution}},
	shorttitle = {Restricting the {Flow}},
	url = {http://arxiv.org/abs/2001.00396},
	abstract = {Attribution methods provide insights into the decision-making of machine learning models like artificial neural networks. For a given input sample, they assign a relevance score to each individual input variable, such as the pixels of an image. In this work we adapt the information bottleneck concept for attribution. By adding noise to intermediate feature maps we restrict the flow of information and can quantify (in bits) how much information image regions provide. We compare our method against ten baselines using three different metrics on VGG-16 and ResNet-50, and find that our methods outperform all baselines in five out of six settings. The method's information-theoretic foundation provides an absolute frame of reference for attribution values (bits) and a guarantee that regions scored close to zero are not necessary for the network's decision. For reviews: https://openreview.net/forum?id=S1xWh1rYwB For code: https://github.com/BioroboticsLab/IBA},
	urldate = {2020-09-19},
	author = {Schulz, Karl and Sixt, Leon and Tombari, Federico and Landgraf, Tim},
	month = may,
	year = {2020},
	note = {arXiv: 2001.00396},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Statistics - Machine Learning, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tim\\Zotero\\storage\\EC7XZ8P2\\Schulz et al. - 2020 - Restricting the Flow Information Bottlenecks for .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\28IXW5D3\\2001.html:text/html}
}

@techreport{wild_social_2020,
	title = {Social networks predict the life and death of honey bees},
	copyright = {© 2020, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2020.05.06.076943v1},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}In many social systems, an individual’s role is reflected by its interactions with other members of the group (Gordon 2010, Pinter-Wollmann et al. 2014, Krause 2015, Farine \&amp; Whitehead 2015). In honey bee colonies (\textit{Apis mellifera}), workers generally perform different tasks as they age, yet there is high behavioral variation in same-aged bees (Seeley 1982, Robinson 1992, Huang and Robinson 1996, Johnson 2010). It is unknown how social interactions within the colony relate to an individual’s tasks throughout her life. We propose a new method to extract a single number from each individual’s interaction patterns in multimodal social networks that captures her current role in the colony. This “network age” is better than biological age at predicting task allocation (+99\%), survival (+157\%), and activity patterns (+44-108\%) and even predicts task allocation up to one week (around a sixth of her typical lifespan) into the future. Network age identifies distinct developmental paths and task changes throughout a bee’s life: We show that individuals change tasks gradually and exhibit high task repeatability, and that same aged bees form stable behavioral subgroups in which they predominantly interact with one another. While we derived interaction networks by automatically tracking a fully tagged colony, we show that tracking only 5\% of the bees is sufficient to extract a meaningful representation of the individuals’ interaction patterns, demonstrating the feasibility of our method for detecting complex social structures with reduced experimental effort. Since network age more accurately predicts task allocation than biological age, it could be used in experimental manipulations to quantify shifts in the timing of task transitions as a response. We extend our method to extract interaction patterns relevant to other attributes of the individuals, such as their mortality, opening up a broad range of possible applications. Our approach is a scalable instrument to study individual behavior through the lens of social interactions over time in honey bees and other complex social systems.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-09-19},
	author = {Wild, Benjamin and Dormagen, David M. and Zachariae, Adrian and Smith, Michael L. and Traynor, Kirsten S. and Brockmann, Dirk and Couzin, Iain D. and Landgraf, Tim},
	month = may,
	year = {2020},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2020.05.06.076943},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\3W7583ZX\\Wild et al. - 2020 - Social networks predict the life and death of hone.pdf:application/pdf;Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\XHQQ2922\\2020.05.06.html:text/html}
}

@article{wario_automatic_2017,
	title = {Automatic detection and decoding of honey bee waggle dances},
	volume = {12},
	issn = {1932-6203},
	url = {http://arxiv.org/abs/1708.06590},
	doi = {10.1371/journal.pone.0188626},
	abstract = {The waggle dance is one of the most popular examples of animal communication. Forager bees direct their nestmates to profitable resources via a complex motor display. Essentially, the dance encodes the polar coordinates to the resource in the field. Unemployed foragers follow the dancer's movements and then search for the advertised spots in the field. Throughout the last decades, biologists have employed different techniques to measure key characteristics of the waggle dance and decode the information it conveys. Early techniques involved the use of protractors and stopwatches to measure the dance orientation and duration directly from the observation hive. Recent approaches employ digital video recordings and manual measurements on screen. However, manual approaches are very time-consuming. Most studies, therefore, regard only small numbers of animals in short periods of time. We have developed a system capable of automatically detecting, decoding and mapping communication dances in real-time. In this paper, we describe our recording setup, the image processing steps performed for dance detection and decoding and an algorithm to map dances to the field. The proposed system performs with a detection accuracy of 90.07{\textbackslash}\%. The decoded waggle orientation has an average error of -2.92\{{\textbackslash}deg\} (\${\textbackslash}pm\$ 7.37\{{\textbackslash}deg\} ), well within the range of human error. To evaluate and exemplify the system's performance, a group of bees was trained to an artificial feeder, and all dances in the colony were automatically detected, decoded and mapped. The system presented here is the first of this kind made publicly available, including source code and hardware specifications. We hope this will foster quantitative analyses of the honey bee waggle dance.},
	number = {12},
	urldate = {2020-09-19},
	journal = {PLOS ONE},
	author = {Wario, Fernando and Wild, Benjamin and Rojas, Raúl and Landgraf, Tim},
	month = dec,
	year = {2017},
	note = {tex.ids: wario\_automatic\_2017
arXiv: 1708.06590},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Quantitative Methods, peer-reviewed},
	pages = {e0188626},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tim\\Zotero\\storage\\DQ8SHPPE\\Wario et al. - 2017 - Automatic detection and decoding of honey bee wagg.pdf:application/pdf;arXiv\:1708.06590 PDF:C\:\\Users\\Tim\\Zotero\\storage\\ZAXSM337\\Wario et al. - 2017 - Automatic detection and decoding of honey bee wagg.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\2C2K56IR\\1708.html:text/html;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\LEA5ML6P\\1708.html:text/html}
}

@inproceedings{sixt_when_2020,
	title = {When {Explanations} {Lie}: {Why} {Many} {Modified} {BP} {Attributions} {Fail}},
	volume = {1},
	shorttitle = {When {Explanations} {Lie}},
	url = {https://proceedings.icml.cc/paper/2020/hash/af21d0c97db2e27e13572cbf59eb343d},
	abstract = {Attribution methods aim to explain a neural network's prediction by highlighting the most relevant image areas. A popular approach is to backpropagate (BP) a custom relevance score using modified rules, rather than the gradient. We analyze an extensive set of modified BP methods: Deep Taylor Decomposition, Layer-wise Relevance Propagation (LRP), Excitation BP, PatternAttribution, DeepLIFT, Deconv, RectGrad, and Guided BP. We find empirically that the explanations of all mentioned methods, except for DeepLIFT, are independent of the parameters of later layers. We provide theoretical insights for this surprising behavior and also analyze why DeepLIFT does not suffer from this limitation. Empirically, we measure how information of later layers is ignored by using our new metric, cosine similarity convergence (CSC). The paper provides a framework to assess the faithfulness of new and existing modified BP methods theoretically and empirically. For code see: https://github.com/berleon/when-explanations-lie},
	language = {en},
	urldate = {2020-09-17},
	booktitle = {Proceedings of the {International} {Conference} on {Machine} {Learning}},
	author = {Sixt, Leon and Granz, Maximilian and Landgraf, Tim},
	year = {2020},
	keywords = {peer-reviewed},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\YIT8BYJJ\\Sixt et al. - 2020 - When Explanations Lie Why Many Modified BP Attrib.pdf:application/pdf;Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\D43FPAPU\\af21d0c97db2e27e13572cbf59eb343d.html:text/html}
}

@article{bierbach_guppies_2020,
	title = {Guppies {Prefer} to {Follow} {Large} ({Robot}) {Leaders} {Irrespective} of {Own} {Size}},
	volume = {8},
	issn = {2296-4185},
	url = {https://www.frontiersin.org/articles/10.3389/fbioe.2020.00441/full},
	doi = {10.3389/fbioe.2020.00441},
	abstract = {Body size is often assumed to determine how successful an individual can lead others with larger individuals being better leaders than smaller ones. But even if larger individuals are more readily followed, body size often correlates with specific behavioral patterns and it is thus unclear whether larger individuals are more often followed than smaller ones because of their size or because they behave in a certain way. To control for behavioral differences among differentially-sized leaders, we used biomimetic robotic fish (Robofish) of different sizes. Live guppies (Poecilia reticulata) are known to interact with Robofish in a similar way as with live conspecifics. Consequently, Robofish may serve as a conspecific-like leader that provides standardized behaviors irrespective of its size. We asked whether larger Robofish leaders are preferentially followed and whether the preferences of followers depend on own body size or risk-taking behavior (‘boldness’). We found that live guppies followed larger Robofish leaders in closer proximity than smaller ones and this pattern was independent of the followers’ own body size as well as risk-taking behavior. Our study shows a ‘bigger is better’ pattern in leadership that is fully independent of behavioral differences among differentially-sized leaders, followers’ own size and risk-taking behavior.},
	language = {English},
	urldate = {2020-09-17},
	journal = {Frontiers in Bioengineering and Biotechnology},
	author = {Bierbach, David and Mönck, Hauke J. and Lukas, Juliane and Habedank, Marie and Romanczuk, Pawel and Landgraf, Tim and Krause, Jens},
	year = {2020},
	note = {Publisher: Frontiers},
	keywords = {biomimetic robots, peer-reviewed, Body Size, Leadership, Poecilia reticulata, Robotic fish},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\I7PZ2KDL\\Bierbach et al. - 2020 - Guppies Prefer to Follow Large (Robot) Leaders Irr.pdf:application/pdf}
}

@article{sixt_rendergan:_2018,
	title = {{RenderGAN}: {Generating} {Realistic} {Labeled} {Data}},
	volume = {5},
	issn = {2296-9144},
	shorttitle = {{RenderGAN}},
	url = {https://www.frontiersin.org/articles/10.3389/frobt.2018.00066/full},
	doi = {10.3389/frobt.2018.00066},
	abstract = {Deep Convolutional Neuronal Networks (DCNNs) are showing remarkable performance on many computer vision tasks. Due to their large parameter space, they require many labeled samples when trained in a supervised setting. The costs of annotating data manually can render the use of DCNNs infeasible. We present a novel framework called RenderGAN that can generate large amounts of realistic, labeled images by combining a 3D model and the Generative Adversarial Network framework. In our approach, image augmentations (e.g. lighting, background, and detail) are learned from unlabeled data such that the generated images are strikingly realistic while preserving the labels known from the 3D model. We apply the RenderGAN framework to generate images of barcode-like markers that are attached to honeybees. Training a DCNN on data generated by the RenderGAN yields considerably better performance than training it on various baselines.},
	language = {English},
	urldate = {2021-03-02},
	journal = {Frontiers in Robotics and AI},
	author = {Sixt, Leon and Wild, Benjamin and Landgraf, Tim},
	year = {2018},
	note = {tex.ids= sixt\_rendergan:\_2018
publisher: Frontiers},
	keywords = {social insects, deep learning, peer-reviewed, Generative Adversarial Networks, markers, unsupervised learning},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\GXKHENIN\\Sixt et al. - 2018 - RenderGAN Generating Realistic Labeled Data.pdf:application/pdf}
}

@article{wild_social_2021,
	title = {Social networks predict the life and death of honey bees},
	volume = {12},
	copyright = {2021 The Author(s)},
	issn = {2041-1723},
	url = {https://www.nature.com/articles/s41467-021-21212-5},
	doi = {10.1038/s41467-021-21212-5},
	abstract = {In complex societies, individuals’ roles are reflected by interactions with other conspecifics. Honey bees (Apis mellifera) generally change tasks as they age, but developmental trajectories of individuals can vary drastically due to physiological and environmental factors. We introduce a succinct descriptor of an individual’s social network that can be obtained without interfering with the colony. This ‘network age’ accurately predicts task allocation, survival, activity patterns, and future behavior. We analyze developmental trajectories of multiple cohorts of individuals in a natural setting and identify distinct developmental pathways and critical life changes. Our findings suggest a high stability in task allocation on an individual level. We show that our method is versatile and can extract different properties from social networks, opening up a broad range of future studies. Our approach highlights the relationship of social interactions and individual traits, and provides a scalable technique for understanding how complex social systems function.},
	language = {en},
	number = {1},
	urldate = {2021-02-17},
	journal = {Nature Communications},
	author = {Wild, Benjamin and Dormagen, David M. and Zachariae, Adrian and Smith, Michael L. and Traynor, Kirsten S. and Brockmann, Dirk and Couzin, Iain D. and Landgraf, Tim},
	month = feb,
	year = {2021},
	note = {Number: 1
Publisher: Nature Publishing Group},
	pages = {1110},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\HLIDDXF4\\Wild et al. - 2021 - Social networks predict the life and death of hone.pdf:application/pdf;Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\U5GHA4FN\\s41467-021-21212-5.html:text/html}
}

@article{landgraf_animal---loop_2021,
	title = {Animal-in-the-{Loop}: {Using} {Interactive} {Robotic} {Conspecifics} to {Study} {Social} {Behavior} in {Animal} {Groups}},
	volume = {4},
	shorttitle = {Animal-in-the-{Loop}},
	url = {https://doi.org/10.1146/annurev-control-061920-103228},
	doi = {10.1146/annurev-control-061920-103228},
	abstract = {Biomimetic robots that replace living social interaction partners can help elucidate the underlying interaction rules in animal groups. Our review focuses on the use of interactive robots that respond dynamically to animal behavior as part of a closed control loop. We discuss the most influential works to date and how they have contributed to our understanding of animal sociality. Technological advances permit the use of robots that can adapt to the situations they face and the conspecifics they encounter, or robots that learn to optimize their social performance from a set of experiences. We discuss how adaptation and learning may provide novel insights into group sociobiology and describe the technical challenges associated with these types of interactive robots. This interdisciplinary field provides a rich set of problems to be tackled by roboticists, machine learning engineers, and control theorists. By cultivating smarter robots, we can usher in an era of more nuanced exploration of animal behavior. Expected final online publication date for the Annual Review of Control, Robotics, and Autonomous Systems, Volume 4 is May 3, 2021. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates.},
	number = {1},
	urldate = {2021-04-21},
	journal = {Annual Review of Control, Robotics, and Autonomous Systems},
	author = {Landgraf, Tim and Gebhardt, Gregor H.W. and Bierbach, David and Romanczuk, Pawel and Musiolek, Lea and Hafner, Verena V. and Krause, Jens},
	year = {2021},
	note = {\_eprint: https://doi.org/10.1146/annurev-control-061920-103228},
	pages = {null},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\ASZJPMCV\\Landgraf et al. - 2021 - Animal-in-the-Loop Using Interactive Robotic Cons.pdf:application/pdf}
}

@article{lukas_consistent_2021,
	title = {Consistent {Behavioral} {Syndrome} {Across} {Seasons} in an {Invasive} {Freshwater} {Fish}},
	volume = {8},
	issn = {2296-701X},
	url = {https://www.frontiersin.org/articles/10.3389/fevo.2020.583670/full?utm_source=researcher_app&utm_medium=referral&utm_campaign=RESR_MRKT_Researcher_inbound},
	doi = {10.3389/fevo.2020.583670},
	abstract = {Understanding the linkage between behavioral types and dispersal tendency has become a pressing issue in light of global change and biological invasions. Here, we explore whether dispersing individuals exhibit behavioral types that differ from those remaining in the source population. We investigated a feral population of guppies (Poecilia reticulata) that undergoes a yearly range shift cycle. Guppies are among the most widespread invasive species in the world, but in temperate regions these tropical fish can only survive in winter-warm freshwaters. Established in a thermally-altered stream in Germany, guppies are confined to a warm-water influx in winter, but can spread to peripheral parts as these become thermally accessible. We sampled fish from the source population and a winter-abandoned site in March, June and August. Fish were tested for boldness, sociability and activity involving open-field tests including interactions with a robotic social partner. Guppies differed consistently among each other in all three traits. Behavioral trait expression in the source population differed across seasons, however, we could not detect differences between source and downstream populations. Instead, all sampled populations exhibited a remarkably stable behavioral syndrome between boldness and activity despite strong seasonal changes in water temperature and associated environmental factors. We conclude that random drift (opposed to personality-biased dispersal) is a more likely dispersal mode for guppies, at least in the investigated stream. In the face of fluctuating environments, guppies seem to be extremely effective in keeping behavioral expressions constant, which could help explain their successful invasion and adaptation to disturbed habitats.},
	language = {English},
	urldate = {2021-06-05},
	journal = {Frontiers in Ecology and Evolution},
	author = {Lukas, Juliane and Kalinkat, Gregor and Miesen, Friedrich Wilhelm and Landgraf, Tim and Krause, Jens and Bierbach, David},
	year = {2021},
	note = {Publisher: Frontiers},
	keywords = {animal personality, Dispersal, Guppy, invasive species, range expansion, thermally altered freshwaters},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\EWKISKSK\\Lukas et al. - 2021 - Consistent Behavioral Syndrome Across Seasons in a.pdf:application/pdf}
}

@article{smith_dominant_2021,
	title = {The dominant axes of lifetime behavioral variation in honey bees},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.04.15.440020v1},
	doi = {10.1101/2021.04.15.440020},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}p{\textgreater}Insect colonies are decentralized systems that employ task allocation, whereby individuals undertake different roles to fulfil colony needs, such as honey bee “nurses”, “nest workers”, and “foragers”. However, the extent to which individuals can be well-classified by discrete “roles”, how they change behavior from day-to-day, over entire lifetimes, and with environmental conditions, is poorly understood. Using long-term automated tracking of over 4,200 individually-identified bees \textit{Apis mellifera}, we use behavioral metrics to quantify and compare behavior. We show that individuals exhibit behavioral variation along two dominant axes that represent nest substrate use and movement within the nest. Across lifetimes, we find that individuals differ in foraging onset, and that certain bees exhibit lifelong consistencies in their movement patterns. Furthermore, we examine a period of sudden nectar availability where the honey stores tripled over 6 days, and see that the colony exhibits a distributed shift in activity that did not require a large-scale colony reorganization. Our quantitative approach shows how collective units differ over days and lifetimes, and how sources of variation and variability contribute to the colony’s robust yet flexible response.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2021-06-05},
	journal = {bioRxiv},
	author = {Smith, Michael L. and Davidson, Jacob D. and Wild, Benjamin and Dormagen, David M. and Landgraf, Tim and Couzin, Iain D.},
	month = apr,
	year = {2021},
	note = {Publisher: Cold Spring Harbor Laboratory
Section: New Results},
	pages = {2021.04.15.440020},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\WMBU33UT\\Smith et al. - 2021 - The dominant axes of lifetime behavioral variation.pdf:application/pdf;Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\FLALGXPX\\2021.04.15.440020v1.html:text/html}
}

@inproceedings{wario_motion_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Motion {Dynamics} of {Foragers} in {Honey} {Bee} {Colonies}},
	isbn = {978-3-030-60376-2},
	doi = {10.1007/978-3-030-60376-2_16},
	abstract = {Information transfer among foragers is key for efficient allocation of work and adaptive responses within a honey bee colony. For information to spread quickly, foragers trying to recruit nestmates via the waggle dance (dancers) must reach as many other non-dancing foragers (followers) as possible. Forager bees may have different drives that influence their motion patterns. For instance, dancer bees need to widely cover the dance floor to recruit nestmates, the more broadly, the higher the food source profitability. Followers may instead move more erratically in the hope of meeting a dance. Overall, a good mixing of individuals is necessary to have flexibility at the level of the colony behavior and optimally respond to changing environmental conditions. We aim to determine the motion pattern that precedes communication events, exploiting a data-driven computational model. To this end, real observation data are used to define nest features such as the dance floor location, shape and size, as well as the foragers’ population size and density distribution. All these characteristics highly correlate with the bees walking pattern and determine the efficiency of information transfer among bees. A simulation environment is deployed to test different mobility patterns and evaluate the adherence with available real-world data. Additionally, we determine under what conditions information transfer is most efficient and effective. Owing to the simulation results, we identify the most plausible mobility pattern to represent the available observations.},
	language = {en},
	booktitle = {Swarm {Intelligence}},
	publisher = {Springer International Publishing},
	author = {Wario, Fernando and Wild, Benjamin and Dormagen, David and Landgraf, Tim and Trianni, Vito},
	editor = {Dorigo, Marco and Stützle, Thomas and Blesa, Maria J. and Blum, Christian and Hamann, Heiko and Heinrich, Mary Katherine and Strobel, Volker},
	year = {2020},
	pages = {203--215},
	file = {Springer Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\4IRTUSBJ\\Wario et al. - 2020 - Motion Dynamics of Foragers in Honey Bee Colonies.pdf:application/pdf}
}

@article{jolles_group-level_2020,
	title = {Group-level patterns emerge from individual speed as revealed by an extremely social robotic fish},
	volume = {16},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rsbl.2020.0436},
	doi = {10.1098/rsbl.2020.0436},
	abstract = {Understanding the emergence of collective behaviour has long been a key research focus in the natural sciences. Besides the fundamental role of social interaction rules, a combination of theoretical and empirical work indicates individual speed may be a key process that drives the collective behaviour of animal groups. Socially induced changes in speed by interacting animals make it difficult to isolate the effects of individual speed on group-level behaviours. Here, we tackled this issue by pairing guppies with a biomimetic robot. We used a closed-loop tracking and feedback system to let a robotic fish naturally interact with a live partner in real time, and programmed it to strongly copy and follow its partner's movements while lacking any preferred movement speed or directionality of its own. We show that individual differences in guppies' movement speed were highly repeatable and in turn shaped key collective patterns: a higher individual speed resulted in stronger leadership, lower cohesion, higher alignment and better temporal coordination of the pairs. By combining the strengths of individual-based models and observational work with state-of-the-art robotics, we provide novel evidence that individual speed is a key, fundamental process in the emergence of collective behaviour.},
	number = {9},
	urldate = {2021-06-05},
	journal = {Biology Letters},
	author = {Jolles, Jolle W. and Weimar, Nils and Landgraf, Tim and Romanczuk, Pawel and Krause, Jens and Bierbach, David},
	month = sep,
	year = {2020},
	note = {Publisher: Royal Society},
	pages = {20200436},
	file = {Submitted Version:C\:\\Users\\Tim\\Zotero\\storage\\H4RYVGFT\\Jolles et al. - 2020 - Group-level patterns emerge from individual speed .pdf:application/pdf}
}

@article{landgraf_socially_2020,
	title = {Socially competent robots: adaptation improves leadership performance in groups of live fish},
	shorttitle = {Socially competent robots},
	url = {http://arxiv.org/abs/2009.06633},
	abstract = {Collective motion is commonly modeled with simple interaction rules between agents. Yet in nature, numerous observables vary within and between individuals and it remains largely unknown how animals respond to this variability, and how much of it may be the result of social responses. Here, we hypothesize that Guppies ({\textbackslash}textit\{Poecilia reticulata\}) respond to avoidance behaviors of their shoal mates and that "socially competent" responses allow them to be more effective leaders. We test this hypothesis in an experimental setting in which a robotic Guppy, called RoboFish, is programmed to adapt to avoidance reactions of its live interaction partner. We compare the leadership performance between socially competent robots and two non-competent control behaviors and find that 1) behavioral variability itself appears attractive and that socially competent robots are better leaders that 2) require fewer approach attempts to 3) elicit longer average following behavior than non-competent agents. This work provides evidence that social responsiveness to avoidance reactions plays a role in the social dynamics of guppies. We showcase how social responsiveness can be modeled and tested directly embedded in a living animal model using adaptive, interactive robots.},
	urldate = {2021-06-05},
	journal = {arXiv:2009.06633 [cs]},
	author = {Landgraf, Tim and Moenck, Hauke J. and Gebhardt, Gregor H. W. and Weimar, Nils and Hocke, Mathis and Maxeiner, Moritz and Musiolek, Lea and Krause, Jens and Bierbach, David},
	month = sep,
	year = {2020},
	note = {arXiv: 2009.06633},
	keywords = {Computer Science - Robotics},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tim\\Zotero\\storage\\VY6N3LRD\\Landgraf et al. - 2020 - Socially competent robots adaptation improves lea.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\LMH9YFLU\\2009.html:text/html}
}

@inproceedings{musiolek_robofish_2020,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Robofish as {Social} {Partner} for {Live} {Guppies}},
	isbn = {978-3-030-64313-3},
	doi = {10.1007/978-3-030-64313-3_26},
	abstract = {Biomimetic robots that are accepted as social partners by animals may help to gain insights into animals’ social interaction skills. Here, we present an experiment using the biomimetic Robofish which resembles live guppies (Poecilia reticulata) - a small tropical freshwater fish. Guppy females were given the opportunity to interact with different open-loop controlled Robofish replicas. We show that guppies interacting with a lifelike Robofish replica scored higher on social interaction variables than did those faced with a simple white cuboid performing the same movements, although this effect weakened with time. Our study exemplifies the use of Robofish as a research tool, providing highly standardized social cues for the study of fish social skills such as imitation and following.},
	language = {en},
	booktitle = {Biomimetic and {Biohybrid} {Systems}},
	publisher = {Springer International Publishing},
	author = {Musiolek, Lea and Hafner, Verena V. and Krause, Jens and Landgraf, Tim and Bierbach, David},
	editor = {Vouloutsi, Vasiliki and Mura, Anna and Tauber, Falk and Speck, Thomas and Prescott, Tony J. and Verschure, Paul F. M. J.},
	year = {2020},
	keywords = {Biorobotics, Fish, Social interaction.},
	pages = {270--274},
	file = {Springer Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\HSJYGGCS\\Musiolek et al. - 2020 - Robofish as Social Partner for Live Guppies.pdf:application/pdf}
}

@article{menzel_guidance_2019,
	title = {Guidance of {Navigating} {Honeybees} by {Learned} {Elongated} {Ground} {Structures}},
	volume = {12},
	issn = {1662-5153},
	url = {https://www.frontiersin.org/articles/10.3389/fnbeh.2018.00322/full},
	doi = {10.3389/fnbeh.2018.00322},
	abstract = {Elongated landscape features like forest edges, rivers, roads or boundaries of fields are particularly salient landmarks for navigating animals. Here we ask how honeybees learn such structures and how they are used during their homing flights after being released at an unexpected location (catch-and-release paradigm). The experiments were performed in two landscapes that differed with respect to their overall structure: a rather feature-less landscape, and one rich in close and far distant landmarks. We tested three different forms of learning: learning during orientation flights, learning during training to a feeding site, and learning during homing flights after release at an unexpected site within the explored area. We found that bees use elongated ground structures, e.g. a field boundary separating two pastures close to the hive (experiment 1), an irrigation channel (experiment 2), a hedgerow along which the bees were trained (experiment 3), a gravel road close to the hive and the feeder (experiment 4), a path along an irrigation channel with its vegetation close to the feeder (experiment 5) and a gravel road along which bees performed their homing flights (experiment 6). Discrimination and generalization between the learned linear landmarks and similar ones in the test area depend on their object properties (irrigation channel, gravel road, hedgerow) and their compass orientation. We conclude that elongated ground structures are embedded into multiple landscape features indicating that memory of these linear structures is one component of bee navigation. Elongated structures interact and compete with other references. Object identification is an important part of this process. The objects are characterized not only by their appearance but also by their alignment in the compass. Their salience is highest if both components are close to what had been learned. High similarity in appearance can compensate for (partial) compass misalignment, and vice versa.},
	language = {English},
	urldate = {2021-06-05},
	journal = {Frontiers in Behavioral Neuroscience},
	author = {Menzel, Randolf and Tison, Lea and Fischer-Nakai, Johannes and Cheeseman, James and Balbuena, Maria Sol and Chen, Xiuxian and Landgraf, Tim and Petrasch, Julian and Polster, Johannes and Greggers, Uwe},
	year = {2019},
	note = {Publisher: Frontiers},
	keywords = {Compass alignment, ground structures, guiding landmarks, navigation, object recognition, sun compass},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\7YTHDVUA\\Menzel et al. - 2019 - Guidance of Navigating Honeybees by Learned Elonga.pdf:application/pdf}
}


@article{worm_electric_2021,
	title = {Electric signal synchronization as a behavioural strategy to generate social attention in small groups of mormyrid weakly electric fish and a mobile fish robot},
	issn = {1432-0770},
	url = {https://doi.org/10.1007/s00422-021-00892-8},
	doi = {10.1007/s00422-021-00892-8},
	abstract = {African weakly electric fish communicate at night by constantly emitting and perceiving brief electrical signals (electric organ discharges, EOD) at variable inter-discharge intervals (IDI). While the waveform of single EODs contains information about the sender’s identity, the variable IDI patterns convey information about its current motivational and behavioural state. Pairs of fish can synchronize their EODs to each other via echo responses, and we have previously formulated a ‘social attention hypothesis’ stating that fish use echo responses to address specific individuals and establish brief dyadic communication frameworks within a group. Here, we employed a mobile fish robot to investigate the behaviour of small groups of up to four Mormyrus rume and characterized the social situations during which synchronizations occurred. An EOD-emitting robot reliably evoked social following behaviour, which was strongest in smaller groups and declined with increasing group size. We did not find significant differences in motor behaviour of M. rume with either an interactive playback (echo response) or a random control playback by the robot. Still, the robot reliably elicited mutual synchronizations with other fish. Synchronizations mostly occurred during relatively close social interactions, usually when the fish that initiated synchronization approached either the robot or another fish from a distance. The results support our social attention hypothesis and suggest that electric signal synchronization might facilitate the exchange of social information during a wide range of social behaviours from aggressive territorial displays to shoaling and even cooperative hunting in some mormyrids.},
	language = {en},
	urldate = {2021-09-13},
	journal = {Biological Cybernetics},
	author = {Worm, Martin and Landgraf, Tim and von der Emde, Gerhard},
	month = aug,
	year = {2021},
	file = {Springer Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\U3SMTJBR\\Worm et al. - 2021 - Electric signal synchronization as a behavioural s.pdf:application/pdf},
}

@article{paffhausen_flying_2021,
	title = {A flying platform to investigate neuronal correlates of navigation in the honey bee ({Apis} mellifera)},
	volume = {15},
	issn = {1662-5153},
	url = {https://www.frontiersin.org/articles/10.3389/fnbeh.2021.690571/abstract},
	doi = {10.3389/fnbeh.2021.690571},
	abstract = {Navigating animals combine multiple perceptual faculties, learn during exploration, retrieve multi-facetted memory contents, and exhibit goal-directedness as an expression of their current needs and motivations. Navigation in insects has been linked to a variety of underlying strategies such as path integration, view familiarity, visual beaconing and goal-directed orientation with respect to previously learned ground structures. Most works, however, study navigation either from a field perspective, analyzing purely behavioral observations, or combine computational models with neurophysiological evidence obtained from lab experiments. The honey bee (Apis mellifera) has long been a popular model in the search for neural correlates of complex behaviors and exhibits extraordinary navigational capabilities. However, the neural basis for bee navigation has not yet been explored under natural conditions. Here, we propose a novel methodology to record from the brain of a copter-mounted honey bee. This way, the animal experiences natural multimodal sensory inputs in a natural environment that is familiar to her. We have developed a miniaturized electrophysiology recording system which is able to record spikes in the presence of time-varying electric noise from the copter’s motors and rotors, and devised an experimental procedure to record from mushroom body extrinsic neurons (MBENs). We analyze the resulting electrophysiological data combined with a reconstruction of the animal’s visual perception and find that the neural activity of MBENs is linked to sharp turns, possibly related to the relative motion of visual features. This method is a significant technological step towards recording brain activity of navigating honey bees under natural conditions. By providing all system specifications in an online repository, we hope to close a methodological gap and stimulate further research informing future computational models of insect navigation.},
	language = {English},
	urldate = {2021-07-13},
	journal = {Frontiers in Behavioral Neuroscience},
	author = {Paffhausen, Benjamin Hans and Petrasch, Julian and Wild, Benjamin and Meurers, Thierry and Schülke, Tobias and Polster, Johannes and Fuchs, Inga and Drexler, Helmut and Kuriatnyk, Oleksandra and Menzel, Randolf and Landgraf, Tim},
	year = {2021},
	note = {Publisher: Frontiers},
	keywords = {navigation, mushroom body, Electrophysiology, Honeybee (Apis mellifera L), naturalistic condition, Neuroethology, Quad copter},
}

@inproceedings{ilgun_bio-hybrid_2021,
	title = {Bio-{Hybrid} {Systems} for {Ecosystem} {Level} {Effects}},
	url = {https://direct.mit.edu/isal/article/doi/10.1162/isal_a_00396/102910/Bio-Hybrid-Systems-for-Ecosystem-Level-Effects},
	doi = {10.1162/isal_a_00396},
	language = {en},
	urldate = {2021-09-13},
	publisher = {MIT Press},
	author = {Ilgün, Asya and Angelov, Kostadin and Stefanec, Martin and Schönwetter-Fuchs, Sarah and Stokanic, Valerin and Vollmann, Jutta and Hofstadler, Daniel N. and Kärcher, Martin H. and Mellmann, Heinrich and Taliaronak, Volha and Kviesis, Armands and Komasilovs, Vitalijs and Becher, Matthias A. and Szopek, Martina and Dormagen, David M. and Barmak, Rafael and Bairaktarov, Erol and Broisin, Matthieu and Thenius, Ronald and Mills, Rob and Nicolis, Stamatios C. and Campo, Alexandre and Zacepins, Aleksejs and Petrov, Sergey and Deneubourg, Jean-Louis and Mondada, Francesco and Landgraf, Tim and Hafner, Verena V. and Schmickl, Thomas},
	month = jul,
	year = {2021},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\SYKQZQ2Q\\Ilgün et al. - 2021 - Bio-Hybrid Systems for Ecosystem Level Effects.pdf:application/pdf},
}

@inproceedings{bierbach_biomimetic_2021,
	title = {Biomimetic robots promote the {3Rs} {Principle} in animal testing},
	url = {https://direct.mit.edu/isal/article/doi/10.1162/isal_a_00375/102921/Biomimetic-robots-promote-the-3Rs-Principle-in},
	doi = {10.1162/isal_a_00375},
	language = {en},
	urldate = {2021-09-13},
	publisher = {MIT Press},
	author = {Bierbach, David and Francisco, Fritz and Lukas, Juliane and Landgraf, Tim and Maxeiner, Moritz and Romanczuk, Pawel and Musiolek, Lea and Hafner, Verena V. and Krause, Jens},
	month = jul,
	year = {2021},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\IFN9HUVQ\\Bierbach et al. - 2021 - Biomimetic robots promote the 3Rs Principle in ani.pdf:application/pdf},
}

@article{klamser_impact_2021,
	title = {Impact of {Variable} {Speed} on {Collective} {Movement} of {Animal} {Groups}},
	url = {http://arxiv.org/abs/2106.00959},
	abstract = {A variety of agent-based models has been proposed to account for the emergence of coordinated collective behavior of animal groups from simple interaction rules. A common, simplifying assumption of such collective movement models, is the consideration of individual agents moving with a constant speed. In this work we critically re-asses this assumption underlying a vast majority of collective movement models. First, we show the omnipresent speed variability observed in different species of live fish and artificial agents (RoboFish). Based on theoretical considerations accounting for inertia and rotational friction, we derive a functional dependence of the turning response of individuals on their instantaneous speed (confirmed by experimental data). We investigate how the interplay of variable speed and speed-dependent turning affects self-organized collective behavior by implementing an agent-based model which accounts for both effects. We show, that besides average speed, the individual speed variability may have a dramatic impact on the emergent collective dynamics, as two groups differing only in their speed variability, and being otherwise identical in all other behavioral parameters, can be in two fundamentally different stationary states. We find that the local coupling between group polarization and individual speed is strongest at the order-disorder transition. Furthermore, we demonstrate a decrease in polarization with group size for groups of individuals with variable speed, and a sudden decrease in mean individual speed at a critical group size (N=4 for Voronoi interactions) linked to a topological transition from an all-to-all to a distributed spatial interaction network. Overall, our work highlights the importance to account for fundamental kinematic constraints in general, and variable speed in particular, when modeling self-organized collective dynamics.},
	urldate = {2021-09-13},
	journal = {arXiv:2106.00959 [physics, q-bio]},
	author = {Klamser, Pascal P. and Gómez-Nava, Luis and Landgraf, Tim and Jolles, Jolle W. and Bierbach, David and Romanczuk, Pawel},
	month = jun,
	year = {2021},
	note = {arXiv: 2106.00959},
	keywords = {Quantitative Biology - Populations and Evolution, Physics - Biological Physics},
	file = {arXiv Fulltext PDF:C\:\\Users\\Tim\\Zotero\\storage\\N2492EK2\\Klamser et al. - 2021 - Impact of Variable Speed on Collective Movement of.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\YH488XWI\\2106.html:text/html},
}

@techreport{wild_learning_2021,
	title = {Learning to embed lifetime social behavior from interaction dynamics},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.biorxiv.org/content/10.1101/2021.09.01.458538v1},
	abstract = {Interactions of individuals in complex social systems give rise to emergent behaviors at the group level. Identifying the functional role that individuals take in the group at a specific time facilitates understanding the dynamics of these emergent processes. An individual’s behavior at a given time can be partially inferred by common factors, such as age, but internal and external factors also substantially influence behavior, making it difficult to disentangle common development from individuality. Here we show that such dependencies on common factors can be used as an implicit bias to learn a temporally consistent representation of a functional role from social interaction networks. Using a unique dataset containing lifetime trajectories of multiple generations of individually-marked honey bees in two colonies, we propose a new temporal matrix factorization model that jointly learns the average developmental path and structured variations of individuals in the social network over their entire lives. Our method yields inherently interpretable embeddings that are biologically relevant and consistent over time, allowing one to compare individuals’ functional roles regardless of when or in which colony they lived. Our method provides a quantitative framework for understanding behavioral heterogeneity in complex social systems, and is applicable to fields such as behavioral biology, social sciences, neuroscience, and information science.
Author summary Group-level emergent behaviors are the result of interactions between individual group members. To understand these social dynamics, one must objectively measure the function of an individual in their group at any given time. Ideally, one would also like to compare individuals from different groups, for example, to measure how specific environmental conditions or other external factors influence group behavior. Unfortunately, such an objective measure is hard to obtain because the group and its dynamics constantly change, making it challenging to define an individual’s role in the group as a function of its actions and interactions. We propose a principled approach to model individuals in complex social systems by considering that function often depends, at least partially, on common factors such as age. The model learns a meaningful and interpretable descriptor for all individuals, and can be used to understand how complex social systems function and the emergence of group behavior.},
	language = {en},
	urldate = {2021-09-13},
	author = {Wild, Benjamin and Dormagen, David M. and Smith, Michael L. and Landgraf, Tim},
	month = sep,
	year = {2021},
	doi = {10.1101/2021.09.01.458538},
	note = {Company: Cold Spring Harbor Laboratory
Distributor: Cold Spring Harbor Laboratory
Label: Cold Spring Harbor Laboratory
Section: New Results
Type: article},
	pages = {2021.09.01.458538},
	file = {Full Text PDF:C\:\\Users\\Tim\\Zotero\\storage\\38R7UH35\\Wild et al. - 2021 - Learning to embed lifetime social behavior from in.pdf:application/pdf;Snapshot:C\:\\Users\\Tim\\Zotero\\storage\\B4IPSCV6\\2021.09.01.458538v1.html:text/html},
}


@article{doran_fish_2021,
	title = {Fish waves as emergent collective antipredator behavior},
	volume = {0},
	issn = {0960-9822},
	url = {https://www.cell.com/current-biology/abstract/S0960-9822(21)01654-7},
	doi = {10.1016/j.cub.2021.11.068},
	language = {English},
	number = {0},
	urldate = {2021-12-23},
	journal = {Current Biology},
	author = {Doran, Carolina and Bierbach, David and Lukas, Juliane and Klamser, Pascal and Landgraf, Tim and Klenz, Haider and Habedank, Marie and Arias-Rodriguez, Lenin and Krause, Stefan and Romanczuk, Pawel and Krause, Jens},
	month = dec,
	year = {2021},
	note = {Publisher: Elsevier},
	file = {Full Text PDF:/Users/tim/Zotero/storage/FJ9HFY7C/Doran et al. - 2021 - Fish waves as emergent collective antipredator beh.pdf:application/pdf;Snapshot:/Users/tim/Zotero/storage/LPIGBMJH/S0960-9822(21)01654-7.html:text/html},
}
